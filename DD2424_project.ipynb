{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DD2424_project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-IqG2lSGXTl"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install torch torchvision\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install skimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGzv33LrYJ7T"
      },
      "source": [
        "# Use this to include your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0bESAB1DcA"
      },
      "source": [
        "cd drive/MyDrive/DL\\ project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJeq_ADlzj76"
      },
      "source": [
        "cd \"src/DL project\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvXcXne6Suvo"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.util import crop\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEizzef7J9e4"
      },
      "source": [
        "path = 'data/images_64_batch'\n",
        "path1 = 'data/images_batch'\n",
        "path_32 = \"data/images_small_batch\"\n",
        "path_256 = \"data/images_256_batch\"\n",
        "\n",
        "path_cifar = \"data/data_batch_1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqH0dJPOKBT5"
      },
      "source": [
        "\n",
        "# Download the 313 Q (ab paris) if it doesn't exist\n",
        "!wget -P \"data/\" -nc https://github.com/junyanz/interactive-deep-colorization/raw/master/data/color_bins/pts_in_hull.npy\n",
        "ab_pairs = np.load(\"data/pts_in_hull.npy\")\n",
        "\n",
        "def softencode(image_lab):\n",
        "  # inspiration taken from https://github.com/foamliu/Colorful-Image-Colorization/blob/f498f5de1b505b056673ccca09fbb133c9e81ed1/data_generator.py#L15\n",
        "  h, w = image_lab.shape[0], image_lab.shape[1]\n",
        "  \n",
        "  # Form ab pairs\n",
        "  a = image_lab[:, :, 1].flatten()\n",
        "  b = image_lab[:, :, 2].flatten()\n",
        "  ab = np.vstack((a,b)).T\n",
        "  \n",
        "  # Get the nearest neighbours and their distances\n",
        "  nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree').fit(ab_pairs)\n",
        "  dist, idx = nn.kneighbors(ab)\n",
        "\n",
        "  # Normalize distance using Gaussian kernel\n",
        "  weights = np.exp(-(dist**2)/(2 * (5 ** 2)))\n",
        "  weights = weights / np.sum(weights, axis=1, keepdims=True)\n",
        "\n",
        "  y = np.zeros((ab.shape[0], ab_pairs.shape[0]))\n",
        "  idx_pts = np.arange(ab.shape[0]).reshape(-1, 1)\n",
        "\n",
        "  y[idx_pts, idx] = weights\n",
        "  y = y.reshape(h, w, ab_pairs.shape[0])\n",
        "  return y\n",
        "\n",
        "def decode(predicted, im):\n",
        "  h, w = predicted.shape[0], predicted.shape[1]\n",
        "  a = ab_pairs[:,0].reshape((1, -1))\n",
        "  b = ab_pairs[:,1].reshape((1, -1))\n",
        "\n",
        "  T = 0.38\n",
        "  predicted = predicted.reshape((h * w, -1))\n",
        "  X = np.exp(np.log(predicted + 1e-8) / T)\n",
        "\n",
        "  X = X / np.sum(X, axis=1, keepdims=True)\n",
        "  Xa = np.sum(X * a, 1).reshape((h, w))\n",
        "  Xb = np.sum(X * b, 1).reshape((h, w))\n",
        "\n",
        "  out = np.zeros((h, w, 3), dtype=np.float32)\n",
        "  out[:, :, 0] = im[:, :, 0]\n",
        "  out[:, :, 1] = Xa\n",
        "  out[:, :, 2] = Xb\n",
        "  return out\n",
        "\n",
        "def load_to_data(path, ratio):\n",
        "  images = pickler.unpickle(path)\n",
        "  #data = np.asarray(images)[:600].reshape(-1, 3, 32, 32)\n",
        "  #data = np.transpose(data, (0, 2, 3, 1))\n",
        "  data = []\n",
        "  for image in images[0:math.floor(ratio*len(images))]:\n",
        "    data.append(np.asarray(image))\n",
        "  \n",
        "  del images\n",
        "\n",
        "  data_lab = []\n",
        "  for d in data:\n",
        "    data_lab.append(rgb2lab(d, illuminant='D50'))\n",
        "\n",
        "  del data\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for d in data_lab:\n",
        "    h, w = d.shape[0], d.shape[1]\n",
        "    #L = d[:,:,0].flatten()\n",
        "    x = d[:,:,0].flatten()\n",
        "    x = x.reshape(h,w,1)\n",
        "    #y = softencode(d)\n",
        "    y = d\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "def load_upsize(path, ratio):\n",
        "  images = pickler.unpickle(path)\n",
        "  data = []\n",
        "\n",
        "  for image in images[0:math.floor(ratio*len(images))]:\n",
        "    image = image.resize([256,256],Image.NEAREST)\n",
        "    data.append(np.asarray(image))\n",
        "\n",
        "  data_lab = []\n",
        "  for d in data: \n",
        "    D = d.reshape(256,256,3)\n",
        "    data_lab.append(rgb2lab(D, illuminant='D50'))\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for d in data_lab:\n",
        "    h, w = d.shape[0], d.shape[1]\n",
        "    L = d[:,:,0].flatten()\n",
        "    x = L\n",
        "    x = x.reshape(h,w,1)\n",
        "    y = softencode(d)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "  return X,Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxQco_qqklmr"
      },
      "source": [
        "# 64x64\n",
        "# X,Y = load_to_data(path, 0.008)\n",
        "# 32x32\n",
        "X, Y = load_to_data(path_32, 0.03)\n",
        "print(len(X), len(Y))\n",
        "print(X[0].shape, Y[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Awa_W-_AEwo"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class model_original(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_original, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True)  #output size \n",
        "        self.conv1_1 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True) #output size \n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_1 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_2 = nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv7  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_1  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_2  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True)\n",
        "        self.conv8_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_end = nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "\n",
        "        self.batch1 = nn.BatchNorm2d(64)\n",
        "        self.batch2 = nn.BatchNorm2d(128)\n",
        "        self.batch3 = nn.BatchNorm2d(256)\n",
        "        self.batch4 = nn.BatchNorm2d(512)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1_1(F.relu(self.conv1(x))))) #block1\n",
        "        x = self.batch2(F.relu(self.conv2_2(F.relu(self.conv2(x))))) #block2\n",
        "        x = self.batch3(F.relu(self.conv3_2(F.relu(self.conv3_1(F.relu(self.conv3(x))))))) #block3\n",
        "        x = self.batch4(F.relu(self.conv4_2(F.relu(self.conv4_1(F.relu(self.conv4(x))))))) #block4\n",
        "        x = self.batch4(F.relu(self.conv5_2(F.relu(self.conv5_1(F.relu(self.conv5(x))))))) #block5\n",
        "        x = self.batch4(F.relu(self.conv6_2(F.relu(self.conv6_1(F.relu(self.conv6(x))))))) #block6\n",
        "        x = self.batch4(F.relu(self.conv7_2(F.relu(self.conv7_1(F.relu(self.conv7(x))))))) #block7\n",
        "        x = self.conv8_end(F.relu(self.conv8_2(F.relu(self.conv8_1(F.relu(self.conv8(x))))))) #block8\n",
        "        #out = self.model_out(self.soft(x))\n",
        "        out = self.soft(x)\n",
        "\n",
        "        return self.upsample4(out)\n",
        "      \n",
        "class model_32(nn.Module): #with 32*32, the size are the same after each block\n",
        "    def __init__(self):\n",
        "        super(model_32, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=True)  #output size \n",
        "        self.conv1_1 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2, bias=True) #output size \n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv3_1 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv7  = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv7_1  = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv7_2  = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv8 = nn.ConvTranspose2d(512, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv8_1 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv8_2 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv8_end = nn.Conv2d(256, 313, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "\n",
        "\n",
        "        self.batch1 = nn.BatchNorm2d(64)\n",
        "        self.batch2 = nn.BatchNorm2d(128)\n",
        "        self.batch3 = nn.BatchNorm2d(256)\n",
        "        self.batch4 = nn.BatchNorm2d(512)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1_1(F.relu(self.conv1(x))))) #block1\n",
        "        x = self.batch2(F.relu(self.conv2_2(F.relu(self.conv2(x))))) #block2\n",
        "        x = self.batch3(F.relu(self.conv3_2(F.relu(self.conv3_1(F.relu(self.conv3(x))))))) #block3\n",
        "        x = self.batch4(F.relu(self.conv4_2(F.relu(self.conv4_1(F.relu(self.conv4(x))))))) #block4\n",
        "        x = self.batch4(F.relu(self.conv5_2(F.relu(self.conv5_1(F.relu(self.conv5(x))))))) #block5\n",
        "        x = self.batch4(F.relu(self.conv6_2(F.relu(self.conv6_1(F.relu(self.conv6(x))))))) #block6\n",
        "        x = self.batch4(F.relu(self.conv7_2(F.relu(self.conv7_1(F.relu(self.conv7(x))))))) #block7\n",
        "        x = self.conv8_end(self.batch3(F.relu(self.conv8_2(F.relu(self.conv8_1(F.relu(self.conv8(x)))))))) #block8\n",
        "        #out = self.model_out(self.soft(x))\n",
        "        out = self.soft(x)\n",
        "\n",
        "        return self.upsample4(out)\n",
        "    \n",
        "    def predict(self, image):\n",
        "      \n",
        "      pass\n",
        "\n",
        "\n",
        "class model_32_reduced(nn.Module): #with 32*32, the size are the same after each block\n",
        "    def __init__(self):\n",
        "        super(model_32_reduced, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=True)  #output size\n",
        "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2, bias=True) #output size \n",
        "        torch.nn.init.kaiming_normal_(self.conv2.weight)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        torch.nn.init.kaiming_normal_(self.conv3.weight)\n",
        "\n",
        "        #self.conv4 = nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        #self.conv7  = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        self.conv8 = nn.ConvTranspose2d(256, 256, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        torch.nn.init.kaiming_normal_(self.conv8.weight)\n",
        "\n",
        "        self.conv8_end = nn.Conv2d(256, 313, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        torch.nn.init.kaiming_normal_(self.conv8_end.weight)\n",
        "\n",
        "\n",
        "        self.batch1 = nn.BatchNorm2d(64)\n",
        "        self.batch2 = nn.BatchNorm2d(128)\n",
        "        self.batch3 = nn.BatchNorm2d(256)\n",
        "        self.batch4 = nn.BatchNorm2d(512)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        torch.nn.init.kaiming_normal_(self.model_out.weight)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1(x))) #block1\n",
        "        x = self.batch2(F.relu(self.conv2(x))) #block2\n",
        "        x = self.batch3(F.relu(self.conv3(x))) #block3\n",
        "        #x = self.batch4(F.relu(self.conv4(x))) #block4\n",
        "        #x = self.batch4(F.relu(self.conv7(x))) #block7\n",
        "        x = self.conv8_end(self.batch3(F.relu(self.conv8(x))))#block8\n",
        "        #out = self.model_out(self.soft(x))\n",
        "        out = self.soft(x)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    def predict(self, image):\n",
        "      \n",
        "      pass\n",
        "\n",
        "class model_64(nn.Module): #with 64*64 input and pooling layers\n",
        "    def __init__(self):\n",
        "        super(model_64, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True)  #output size \n",
        "        self.conv1_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True) #output size \n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv7  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_1  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_2  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_end = nn.Conv2d(256, 313, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "\n",
        "        self.batch1 = nn.BatchNorm2d(64)\n",
        "        self.batch2 = nn.BatchNorm2d(128)\n",
        "        self.batch3 = nn.BatchNorm2d(256)\n",
        "        self.batch4 = nn.BatchNorm2d(512)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1_1(F.relu(self.conv1(x))))) #block1\n",
        "        x = self.batch2(F.relu(self.conv2_2(F.relu(self.conv2(x))))) #block2\n",
        "        x = self.batch3(F.relu(self.conv3_2(F.relu(self.conv3_1(F.relu(self.conv3(x))))))) #block3\n",
        "        x = self.batch4(F.relu(self.conv4_2(F.relu(self.conv4_1(F.relu(self.conv4(x))))))) #block4\n",
        "        x = self.batch4(F.relu(self.conv5_2(F.relu(self.conv5_1(F.relu(self.conv5(x))))))) #block5\n",
        "        x = self.batch4(F.relu(self.conv6_2(F.relu(self.conv6_1(F.relu(self.conv6(x))))))) #block6\n",
        "        x = self.batch4(F.relu(self.conv7_2(F.relu(self.conv7_1(F.relu(self.conv7(x))))))) #block7\n",
        "        x = self.conv8_end(self.batch3(F.relu(self.conv8_2(F.relu(self.conv8_1(F.relu(self.conv8(x)))))))) #block8\n",
        "        out = self.model_out(self.soft(x))\n",
        "        #out = self.soft(x)\n",
        "\n",
        "        return self.upsample4(out)\n",
        "    \n",
        "    def predict(self, image):\n",
        "      \n",
        "      pass\n",
        "\n",
        "\n",
        "class model_64_nopool(nn.Module): #with 64*64 input and pooling layers\n",
        "    def __init__(self):\n",
        "        super(model_64_nopool, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True)  #output size \n",
        "        self.conv1_1 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "        #self.pool1 = nn.MaxPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True) #output size \n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        #self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_1 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv6_2 = nn.Conv2d(512, 512, kernel_size=5, dilation=2, stride=1, padding=2, bias=True)\n",
        "        self.conv7  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_1  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv7_2  = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv8_end = nn.Conv2d(256, 313, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "\n",
        "        self.batch1 = nn.BatchNorm2d(64)\n",
        "        self.batch2 = nn.BatchNorm2d(128)\n",
        "        self.batch3 = nn.BatchNorm2d(256)\n",
        "        self.batch4 = nn.BatchNorm2d(512)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch1(F.relu(self.conv1_1(F.relu(self.conv1(x))))) #block1\n",
        "        x = self.batch2(F.relu(self.conv2_2(F.relu(self.conv2(x))))) #block2\n",
        "        x = self.batch3(F.relu(self.conv3_2(F.relu(self.conv3_1(F.relu(self.conv3(x))))))) #block3\n",
        "        x = self.batch4(F.relu(self.conv4_2(F.relu(self.conv4_1(F.relu(self.conv4(x))))))) #block4\n",
        "        x = self.batch4(F.relu(self.conv5_2(F.relu(self.conv5_1(F.relu(self.conv5(x))))))) #block5\n",
        "        x = self.batch4(F.relu(self.conv6_2(F.relu(self.conv6_1(F.relu(self.conv6(x))))))) #block6\n",
        "        x = self.batch4(F.relu(self.conv7_2(F.relu(self.conv7_1(F.relu(self.conv7(x))))))) #block7\n",
        "        x = self.conv8_end(self.batch3(F.relu(self.conv8_2(F.relu(self.conv8_1(F.relu(self.conv8(x)))))))) #block8\n",
        "        #out = self.model_out(self.soft(x))\n",
        "        out = self.soft(x)\n",
        "\n",
        "        return self.upsample4(out)\n",
        "    \n",
        "    def predict(self, image):\n",
        "      \n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj8AYD2cN7C1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model_32_reduced()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyvgCLP_VrLO"
      },
      "source": [
        "learning_rate = 0.01\n",
        "num_epochs = 120\n",
        "batch_size = 50\n",
        "import torch.optim as optim\n",
        "\n",
        "# create a stochastic gradient descent optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
        "\n",
        "# create a loss function\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def multinomial_cross_entropy_loss(y_true, y_pred):\n",
        "    y_true = softencode(y_true)\n",
        "    y_true = torch.from_numpy(y_true).float().to(device) \n",
        "\n",
        "    idx_max = torch.argmax(y_true, -1).reshape(-1)\n",
        "    prior_t = torch.from_numpy(prior_factor).float().to(device)\n",
        "\n",
        "    weights = torch.gather(prior_t, 0, idx_max).reshape(32, 32)\n",
        "\n",
        "    y_pred = torch.clamp(y_pred, 1e-8, 1-1e-8)\n",
        "    sum = torch.sum(y_true * y_pred.log(), -1)\n",
        "    \n",
        "    return -1 * torch.sum(weights * sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrEPjzPMIs29"
      },
      "source": [
        "#import tensorflow as tf\n",
        "#from torch.autograd import Variable\n",
        "#cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "def ker_loss(y_true, y_pred):\n",
        "    y_true = softencode(y_true)\n",
        "    y_pred = unnormalize_label(y_pred).cpu().detach().numpy()\n",
        "    loss = torch.tensor(cce(y_true, y_pred).numpy())\n",
        "    loss = Variable(loss, requires_grad = True)\n",
        "    return loss.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZCp3Y0QAOnQ"
      },
      "source": [
        "ab_pairs = np.load(\"data/pts_in_hull.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZhngCogCXyO"
      },
      "source": [
        "# Adapted from https://github.com/foamliu/Colorful-Image-Colorization/blob/master/class_rebal.py\n",
        "\n",
        "## Prior Probs\n",
        "Xab = np.asarray(Y[:])[:, :, :, 1:]\n",
        "\n",
        "print(Xab.shape)\n",
        "\n",
        "Xa = np.ravel(Xab[:, :, :, 0])\n",
        "Xb = np.ravel(Xab[:, :, :, 1])\n",
        "X_ab = np.vstack((Xa, Xb)).T\n",
        "\n",
        "# Get the nearest neighbours and their distances\n",
        "nn = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(ab_pairs)\n",
        "dist, idx = nn.kneighbors(X_ab)\n",
        "\n",
        "ind = np.ravel(idx)\n",
        "counts = np.bincount(ind)\n",
        "idxs = np.nonzero(counts)[0]\n",
        "\n",
        "prior_prob = np.zeros((ab_pairs.shape[0]))\n",
        "\n",
        "prior_prob[idxs] = counts[idxs]\n",
        "\n",
        "# We turn this into a color probability\n",
        "prior_prob = prior_prob / (np.sum(prior_prob))\n",
        "np.save(\"priors.npy\", prior_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-DoubD_GqdE"
      },
      "source": [
        "## Smoooth the prior probs\n",
        "\n",
        "from scipy.signal import gaussian, convolve\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "prior_prob += 1E-3 * np.min(prior_prob)\n",
        "# renormalize\n",
        "prior_prob = prior_prob / (1.0 * np.sum(prior_prob))\n",
        "\n",
        "# Smooth with gaussian\n",
        "f = interp1d(np.arange(prior_prob.shape[0]), prior_prob)\n",
        "xx = np.linspace(0, prior_prob.shape[0] - 1, 1000)\n",
        "yy = f(xx)\n",
        "window = gaussian(2000, 5)\n",
        "smoothed = convolve(yy, window / window.sum(), mode='same')\n",
        "fout = interp1d(xx, smoothed)\n",
        "prior_prob_smoothed = np.array([fout(i) for i in range(prior_prob.shape[0])])\n",
        "prior_prob_smoothed = prior_prob_smoothed / np.sum(prior_prob_smoothed)\n",
        "\n",
        "# Save\n",
        "np.save(\"prior_prob_smoothed.npy\", prior_prob_smoothed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6NPAy2xMvhU"
      },
      "source": [
        "u = np.ones_like(prior_prob_smoothed)\n",
        "u = u / np.sum(1.0 * u)\n",
        "\n",
        "prior_factor = (1 - 0.5) * prior_prob_smoothed + 0.5 * u\n",
        "prior_factor = np.power(prior_factor, -1)\n",
        "\n",
        "# renormalize\n",
        "prior_factor = prior_factor / (np.sum(prior_factor * prior_prob_smoothed))\n",
        "\n",
        "np.save(\"prior_factor.npy\", prior_factor)\n",
        "print(prior_factor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ij9AWtv_rZg"
      },
      "source": [
        "#Normalize in the same way as the original paper\n",
        "\n",
        "data_cent = 60\n",
        "data_norm = 100\n",
        "label_norm = 110\n",
        "\n",
        "def normalize_data(data):\n",
        "  return (data-data_cent)/data_norm\n",
        "\n",
        "def unnormalize_data(data):\n",
        "  return data_norm*data+data_cent\n",
        "\n",
        "def normalize_label(label):\n",
        "  return label/label_norm\n",
        "\n",
        "def unnormalize_label(label):\n",
        "  return label*label_norm\n",
        "\n",
        "\n",
        "\n",
        "#split train&test\n",
        "train_data = X[0:math.floor(len(X)*0.8)]\n",
        "train_label = Y[0:math.floor(len(X)*0.8)]\n",
        "test_data = X[math.floor(len(X)*0.8):]\n",
        "test_label = Y [math.floor(len(X)*0.8):]\n",
        "print(train_data[0].shape)\n",
        "#convert to numpy arrays and transpose into correct order to CNN\n",
        "train_data = np.asarray(train_data)\n",
        "train_label = np.asarray(train_label)\n",
        "test_data = np.asarray(test_data)\n",
        "test_label = np.asarray(test_label)\n",
        "print(train_data.shape)\n",
        "train_data = np.transpose(train_data,(0,3,1,2) )\n",
        "train_label = np.transpose(train_label,(0,3,1,2) )\n",
        "test_data = np.transpose(test_data,(0,3,1,2) )\n",
        "test_label = np.transpose(test_label,(0,3,1,2) )\n",
        "print(train_data.shape)\n",
        "train_data = normalize_data(train_data)\n",
        "#train_label = normalize_label(train_label) # Normalize labels after softencoding in loss function\n",
        "test_data = normalize_data(test_data)\n",
        "#test_label = normalize_label(test_label) # Normalize labels after softencoding in loss function\n",
        "\n",
        "print(train_data.shape)\n",
        "#Send data to device\n",
        "train_images = torch.from_numpy(train_data).float().to(device)\n",
        "#train_labels = torch.from_numpy(train_label).float().to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzgjPih3ILV"
      },
      "source": [
        "for epoch in range(1, num_epochs+1):\n",
        "  per = torch.randperm(train_images.shape[0])\n",
        "  if epoch % 5 == 0 or epoch == 1:\n",
        "    # Show decoded image\n",
        "    H, W = train_images.shape[-1], train_images.shape[-2]\n",
        "    train_im = np.random.randint(0, 500)\n",
        "    train_example = train_images[train_im]\n",
        "    train_l = np.transpose(train_label[train_im], (1, 2, 0))\n",
        "\n",
        "    train_example = train_example.reshape(1, 1, H, W)\n",
        "    train_pred = model(train_example).reshape([H, W, 313])\n",
        "    train_pred = decode(train_pred.cpu().detach().numpy(), train_l)\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True)\n",
        "    ax1.imshow(lab2rgb(train_l))\n",
        "    ax1.set_title(\"Original\")\n",
        "    ax2.imshow(lab2rgb(train_pred))\n",
        "    ax2.set_title(\"Decoded:\")\n",
        "    plt.show()\n",
        "\n",
        "  for i in range(0, train_images.shape[0], batch_size):\n",
        "    \n",
        "    ind = per[i:i+batch_size]\n",
        "    batch_x, target_batch_y = train_images[ind,:,:,:], train_label[ind,:,:,:]\n",
        "    \n",
        "    torch.cuda.current_stream().synchronize()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x)\n",
        "\n",
        "    # Supposed to be 32 x 32 x 313\n",
        "    out_t = torch.reshape(output, (ind.shape[0], 32, 32, 313))\n",
        "    #out_t = torch.reshape(output, (ind.shape[0], 256, 256, 313))\n",
        "\n",
        "    # Supposed to be 32 x 32 x 3\n",
        "    true_t = np.transpose(target_batch_y, (0, 2, 3, 1))\n",
        "    #true_t = torch.from_numpy(true_t).to(device)\n",
        "    \n",
        "    loss = 0\n",
        "    for j in range(ind.shape[0]):\n",
        "      loss += multinomial_cross_entropy_loss(true_t[j], out_t[j])\n",
        "    loss /= ind.shape[0]\n",
        "\n",
        "    #loss = criterion(true_t, out_t)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "    print(\"\\rIteration:\", i, \"/\", train_images.shape[0], \"Loss:\", loss.item(), end=\"\")\n",
        "\n",
        "  print(\"\\rEpoch:\", epoch, \"/\", num_epochs, \"Loss:\", loss.item(), end=\"\\n\")\n",
        "\n",
        "torch.save(model, \"small_model_0.1\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ayj5EgeuH9C"
      },
      "source": [
        "del train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KON-6KG_Foib"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KrBWgCoEcs6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Put test inputs onto GPU\n",
        "test_images = torch.from_numpy(test_data).float().to(device)\n",
        "H, W = test_images.shape[-1], test_images.shape[-2]\n",
        "print(H, W)\n",
        "\n",
        "### Pick one test example\n",
        "test_number = np.random.randint(0, 100)\n",
        "test_example = test_images[test_number]\n",
        "test_l = np.transpose(test_label[test_number], (1, 2, 0))\n",
        "\n",
        "### Pass the test input into the model\n",
        "# Reshape input for CNN\n",
        "test_example = test_example.reshape(1, 1, H, W)\n",
        "\n",
        "prediction = model(test_example).reshape([H, W, 313]).cpu().detach().numpy()\n",
        "pred_decoded = decode(prediction, test_l)\n",
        "\n",
        "print(np.min(test_l[:,:,1:]), np.max(test_l[:, :, 1:]))\n",
        "print(np.min(pred_decoded[:,:,1:]), np.max(pred_decoded[:, :, 1:]))\n",
        "\n",
        "### Plot the test input\n",
        "im = test_example.cpu().numpy().reshape(H, W)\n",
        "plt.imshow(lab2rgb(test_l))\n",
        "plt.show()\n",
        "\n",
        "### Plot the prediction\n",
        "plt.imshow(lab2rgb(pred_decoded))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0xLO8ubck_"
      },
      "source": [
        "dummy = np.zeros((H, W, 1))\n",
        "dummy[:,:,0] = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvBvZhT157Rp"
      },
      "source": [
        "pred1 = prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H63CQo0B59Mz"
      },
      "source": [
        "pred2 = prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLKN7eeSeJz1"
      },
      "source": [
        "print(np.sum(pred1[0,0]), np.max(pred1))\n",
        "print(np.sum(pred2), np.max(pred2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ_5VY-basQ6"
      },
      "source": [
        "plt.imshow(lab2rgb(decode(pred1, dummy)))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(lab2rgb(decode(pred2, dummy)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZTiYorF6CDJ"
      },
      "source": [
        "#t = (pred1 - pred2)**2\n",
        "#print(np.min(t), np.max(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKKLuE6qEgrk"
      },
      "source": [
        "### CONVERT 32 x 32 to 256 x 256\n",
        "#data = []\n",
        "#images = pickler.unpickle(path1)\n",
        "#for image in images:\n",
        "  #image = image.resize([256,256], Image.NEAREST)\n",
        "  #image = image.resize([64,64], Image.NEAREST)\n",
        "  #data.append(np.asarray(image))\n",
        "\n",
        "#pickler.inpickle(\"data/images_256_batch\", data)\n",
        "#pickler.inpickle(\"data/images_64_batch\", data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nvy0224xc87"
      },
      "source": [
        "#model_path = \"small_model_0.1\"\n",
        "#model = torch.load(model_path)\n",
        "#model.eval()\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}